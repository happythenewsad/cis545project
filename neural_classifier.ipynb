{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, \"./code/\")\n",
    "from Eval import Eval\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_pickle('data/traindata.pickle')\n",
    "valdata   = pd.read_pickle('data/valdata.pickle')\n",
    "testdata  = pd.read_pickle('data/testdata.pickle')\n",
    "\n",
    "def numerize(item):\n",
    "    if item == 'MWS':\n",
    "        return 0\n",
    "    elif item == 'HPL':\n",
    "        return 1\n",
    "    elif item == 'EAP':\n",
    "        return 2\n",
    "    raise ValueError('Author not recognized:', item)\n",
    "   \n",
    "encoder = sklearn.preprocessing.LabelEncoder()\n",
    "encoder.fit(traindata.author)\n",
    "\n",
    "\n",
    "Y_train = tf.keras.utils.to_categorical(encoder.transform(traindata.author))#np.array([numerize(x) for x in list(traindata.author)])\n",
    "Y_val = tf.keras.utils.to_categorical(encoder.transform(valdata.author))#np.array([numerize(x) for x in list(valdata.author)])\n",
    "Y_test = tf.keras.utils.to_categorical(encoder.transform(testdata.author))#np.array([numerize(x) for x in list(testdata.author)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EAP', 'HPL', 'MWS'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textual feature engineering\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=STOPWORDS, max_features=1500)\n",
    "\n",
    "X_train = train_text_feats = vectorizer.fit_transform(traindata.text).todense()\n",
    "X_val = val_text_feats = vectorizer.transform(valdata.text).todense() \n",
    "X_test = test_text_feats = vectorizer.transform(testdata.text).todense() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create a sigmoid layer:\n",
    "# tf.keras.layers.Dense(64, activation='sigmoid')\n",
    "# # Or:\n",
    "# tf.keras.layers.Dense(64, activation=tf.sigmoid)\n",
    "\n",
    "# # A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "# tf.keras.layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# # A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "# tf.keras.layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# # A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "# tf.keras.layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# # A linear layer with a bias vector initialized to 2.0s:\n",
    "# tf.keras.layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by keras docs example: https://www.tensorflow.org/guide/keras#input_numpy_data\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "tf.keras.layers.Dense(100, activation='relu'),\n",
    "# Add another:\n",
    "tf.keras.layers.Dense(100, activation='relu'),\n",
    "# Add a softmax layer with 10 output units:\n",
    "tf.keras.layers.Dense(3, activation='softmax')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15664 samples, validate on 1958 samples\n",
      "Epoch 1/10\n",
      "15664/15664 [==============================] - 3s 180us/step - loss: 0.8209 - categorical_accuracy: 0.6131 - val_loss: 0.6369 - val_categorical_accuracy: 0.7298\n",
      "Epoch 2/10\n",
      "15664/15664 [==============================] - 2s 144us/step - loss: 0.5849 - categorical_accuracy: 0.7583 - val_loss: 0.6159 - val_categorical_accuracy: 0.7339\n",
      "Epoch 3/10\n",
      "15664/15664 [==============================] - 2s 144us/step - loss: 0.5206 - categorical_accuracy: 0.7888 - val_loss: 0.6217 - val_categorical_accuracy: 0.7477\n",
      "Epoch 4/10\n",
      "15664/15664 [==============================] - 2s 146us/step - loss: 0.4516 - categorical_accuracy: 0.8177 - val_loss: 0.7041 - val_categorical_accuracy: 0.7308\n",
      "Epoch 5/10\n",
      "15664/15664 [==============================] - 2s 141us/step - loss: 0.3730 - categorical_accuracy: 0.8502 - val_loss: 0.8460 - val_categorical_accuracy: 0.7201\n",
      "Epoch 6/10\n",
      "15664/15664 [==============================] - 2s 140us/step - loss: 0.2957 - categorical_accuracy: 0.8827 - val_loss: 1.0409 - val_categorical_accuracy: 0.6956\n",
      "Epoch 7/10\n",
      "15664/15664 [==============================] - 2s 149us/step - loss: 0.2291 - categorical_accuracy: 0.9109 - val_loss: 1.2763 - val_categorical_accuracy: 0.6987\n",
      "Epoch 8/10\n",
      "15664/15664 [==============================] - 2s 156us/step - loss: 0.1749 - categorical_accuracy: 0.9328 - val_loss: 1.5121 - val_categorical_accuracy: 0.7058\n",
      "Epoch 9/10\n",
      "15664/15664 [==============================] - 2s 140us/step - loss: 0.1383 - categorical_accuracy: 0.9495 - val_loss: 1.8226 - val_categorical_accuracy: 0.6905\n",
      "Epoch 10/10\n",
      "15664/15664 [==============================] - 2s 143us/step - loss: 0.1167 - categorical_accuracy: 0.9593 - val_loss: 1.9922 - val_categorical_accuracy: 0.6854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3293ac50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns loss, accuracy\n",
    "result = model.predict(X_test, verbose=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lookup = {}\n",
    "for idx, label in enumerate(encoder.classes_):\n",
    "    label_lookup[idx] = label\n",
    "label_lookup\n",
    "\n",
    "def best_label(row, lookup):\n",
    "    mx = max(row)\n",
    "    return lookup[list(row).index(mx)]\n",
    "\n",
    "preds = [best_label(x, label_lookup) for x in result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6898313745528871\n"
     ]
    }
   ],
   "source": [
    "accuracy = Eval.get_accuracy(preds, list(testdata.author))\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished at:  Sun Dec  9 00:42:41 2018\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timenow = time.asctime( time.localtime(time.time()) )\n",
    "print(\"Finished at: \", timenow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
