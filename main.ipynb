{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/peterkong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# local code\n",
    "sys.path.insert(1, \"./code/\")\n",
    "from Utils import Utils # student's library\n",
    "from Eval import Eval # student's library\n",
    "from Extract import Extract # student's library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "#train_df.id.nunique()\n",
    "# 19579\n",
    "\n",
    "#train_df.author.unique()\n",
    "# array(['EAP', 'HPL', 'MWS'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 0, 'id': 0, 'text': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Utils.check_for_nulls(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data\n",
    "\n",
    "# regular data\n",
    "#     train: 19580 * .9 rows\n",
    "#     test:  8393 rows\n",
    "#     val:   19580 * .1 rows\n",
    "\n",
    "\n",
    "if os.path.isfile('data/traindata.pickle'):\n",
    "    traindata = pd.read_pickle('data/traindata.pickle')\n",
    "    valdata   = pd.read_pickle('data/valdata.pickle')\n",
    "    testdata  = pd.read_pickle('data/testdata.pickle')\n",
    "else: \n",
    "    VAL_IDX  = math.ceil(len(train_df) * .8)\n",
    "    TEST_IDX = math.ceil(len(train_df) * .9)\n",
    "\n",
    "    traindata = train_df[:VAL_IDX]\n",
    "    valdata   = train_df[VAL_IDX:TEST_IDX]\n",
    "    testdata  = train_df[TEST_IDX:]\n",
    "\n",
    "    print(VAL_IDX, TEST_IDX)\n",
    "\n",
    "    traindata.to_pickle('data/traindata.pickle')\n",
    "    valdata.to_pickle('data/valdata.pickle')\n",
    "    testdata.to_pickle('data/testdata.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindata: 15664, valdata: 1958, testdata: 1957\n"
     ]
    }
   ],
   "source": [
    "print(\"traindata: {}, valdata: {}, testdata: {}\".format(len(traindata), len(valdata), len(testdata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammatical feature engineering \n",
    "# we want to include stopwords here\n",
    "\n",
    "if os.path.isfile('data/train_gram_feats.pickle'):\n",
    "    print(\"reading gram feats from pickle\")\n",
    "    train_gram_feats_df = pd.read_pickle('data/train_gram_feats_df.pickle')\n",
    "    val_gram_feats_df   = pd.read_pickle('data/val_gram_feats_df.pickle')\n",
    "    test_gram_feats_df  = pd.read_pickle('data/test_gram_feats_df.pickle')\n",
    "else:\n",
    "    seq_no = None\n",
    "    train_gram_feats_df = Extract.gram_feats(traindata.text, None, seq_no)\n",
    "\n",
    "    # need to remember so that val/test process\n",
    "    # does not add additional columns\n",
    "    GRAM_FEAT_LIST = list(train_gram_feats_df.columns)\n",
    "\n",
    "    val_gram_feats_df = Extract.gram_feats(valdata.text, GRAM_FEAT_LIST, seq_no)\n",
    "    test_gram_feats_df = Extract.gram_feats(testdata.text, GRAM_FEAT_LIST, seq_no)\n",
    "\n",
    "    # there are 21 columns excluding sequence columns \n",
    "    # 7ary sequence columns can generate up to 2187\n",
    "    \n",
    "    train_gram_feats_df.to_pickle('data/train_gram_feats_df.pickle')\n",
    "    val_gram_feats_df.to_pickle('data/val_gram_feats_df.pickle')\n",
    "    test_gram_feats_df.to_pickle('data/test_gram_feats_df.pickle')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15664, 23)\n",
      "(1958, 23)\n",
      "(1957, 23)\n"
     ]
    }
   ],
   "source": [
    "# removes a singleton feature\n",
    "for df in train_gram_feats_df, val_gram_feats_df, test_gram_feats_df:\n",
    "    if 'SYM_count' in list(df.columns):\n",
    "        df.drop('SYM_count', axis=1, inplace=True)\n",
    "        \n",
    "print(train_gram_feats_df.shape)\n",
    "print(val_gram_feats_df.shape)\n",
    "print(test_gram_feats_df.shape)\n",
    "\n",
    "#set(GRAM_FEAT_LIST) - set(list(val_gram_feats_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textual feature engineering\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=STOPWORDS, max_features=1500)\n",
    "\n",
    "train_text_feats = vectorizer.fit_transform(traindata.text)\n",
    "Y_train = traindata.author \n",
    "\n",
    "val_text_feats = vectorizer.transform(valdata.text) \n",
    "Y_val = list(valdata.author)\n",
    "\n",
    "test_text_feats = vectorizer.transform(testdata.text) \n",
    "Y_test = list(testdata.author)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15664, 1500)\n",
      "(1958, 1500)\n",
      "(1957, 1500)\n"
     ]
    }
   ],
   "source": [
    "#convert text feats to pandas\n",
    "\n",
    "cols = [\"text_\" + str(x) for x in range(train_text_feats.shape[1])]\n",
    "\n",
    "train_text_feats_df = pd.DataFrame(train_text_feats.todense(), index=None, columns=cols)\n",
    "val_text_feats_df = pd.DataFrame(val_text_feats.todense(), index=None, columns=cols)\n",
    "test_text_feats_df = pd.DataFrame(test_text_feats.todense(), index=None, columns=cols)\n",
    "\n",
    "print(train_text_feats_df.shape)\n",
    "print(val_text_feats_df.shape)\n",
    "print(test_text_feats_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist to disk\n",
    "if not os.path.isfile('data/train_text_feats_df.pickle'):\n",
    "    train_text_feats_df.to_pickle('data/train_text_feats_df.pickle')\n",
    "    val_text_feats_df.to_pickle('data/val_text_feats_df.pickle')\n",
    "    test_text_feats_df.to_pickle('data/test_text_feats_df.pickle')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_0</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>text_3</th>\n",
       "      <th>text_4</th>\n",
       "      <th>text_5</th>\n",
       "      <th>text_6</th>\n",
       "      <th>text_7</th>\n",
       "      <th>text_8</th>\n",
       "      <th>text_9</th>\n",
       "      <th>...</th>\n",
       "      <th>text_590</th>\n",
       "      <th>text_591</th>\n",
       "      <th>text_592</th>\n",
       "      <th>text_593</th>\n",
       "      <th>text_594</th>\n",
       "      <th>text_595</th>\n",
       "      <th>text_596</th>\n",
       "      <th>text_597</th>\n",
       "      <th>text_598</th>\n",
       "      <th>text_599</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.293483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_0  text_1  text_2  text_3  text_4  text_5    text_6  text_7  text_8  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0  0.293483     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "\n",
       "   text_9    ...     text_590  text_591  text_592  text_593  text_594  \\\n",
       "0     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "1     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "2     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "3     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "4     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   text_595  text_596  text_597  text_598  text_599  \n",
       "0  0.000000       0.0       0.0       0.0       0.0  \n",
       "1  0.000000       0.0       0.0       0.0       0.0  \n",
       "2  0.000000       0.0       0.0       0.0       0.0  \n",
       "3  0.263912       0.0       0.0       0.0       0.0  \n",
       "4  0.000000       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 600 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_feats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-1163ed64497c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#TaggedDocument does not filter or stem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTaggedDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# gensim feature engineering\n",
    "import numpy as np\n",
    "import gensim\n",
    "GENSIM = True\n",
    "\n",
    "if GENSIM:\n",
    "\n",
    "    #https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "    from gensim.test.utils import common_texts\n",
    "    from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "    #TaggedDocument does not filter or stem\n",
    "\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(list(X_val.text))]\n",
    "    model = Doc2Vec(documents, vector_size=100, window=2, min_count=1, workers=4)\n",
    "\n",
    "    train_gensim = np.array([model.infer_vector(x) for x in list(X_train.text)])\n",
    "    val_gensim = np.array([model.infer_vector(x) for x in list(X_val.text)])\n",
    "    test_gensim = np.array([model.infer_vector(x) for x in list(X_test.text)])\n",
    "\n",
    "    # numpy to pandas\n",
    "    cols = [\"gensim_\" + str(x) for x in range(len(train_gensim[0]))]\n",
    "\n",
    "    X_train = pd.DataFrame(train_gensim, index=None, columns=cols)\n",
    "    X_val = pd.DataFrame(val_gensim, index=None, columns=cols)\n",
    "    X_test = pd.DataFrame(test_gensim, index=None, columns=cols)\n",
    "    \n",
    "# gensim didn't help. so we're settling on tfidf extual features for now, and will explore neural models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15664, 1500)\n",
      "(1958, 1500)\n",
      "(1957, 1500)\n"
     ]
    }
   ],
   "source": [
    "# concatenating features\n",
    "\n",
    "    #traindata.text.to_frame() for gensim\n",
    "    #val_gram_feats_df.fillna(0)\n",
    "X_train = train_text_feats_df.fillna(0)\n",
    "X_val = val_text_feats_df.fillna(0)\n",
    "X_test = test_text_feats_df.fillna(0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame({'foo':[1,3,99], 'bar':[2,4,7]})\n",
    "\n",
    "def transform(df):\n",
    "    def xform(x, **kwargs):\n",
    "        return (x - avg) / stdv\n",
    "\n",
    "    for col in df.columns:\n",
    "        stdv = df[col].std()\n",
    "        avg = df[col].mean()\n",
    "        df[col] = df[col].apply(xform, avg=avg, stdv=stdv)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell throws on non numerical columns\n",
    "\n",
    "# X_train = transform(X_train).fillna(0)\n",
    "# X_val = transform(X_val).fillna(0)\n",
    "# X_test = transform(X_test).fillna(0)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_val.shape)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity checking\n",
    "assert(list(X_train.columns) == list(X_val.columns))\n",
    "assert(list(X_train.columns) == list(X_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22947"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lex = Utils.build_lexicon(traindata.text, STOPWORDS)\n",
    "# len(lex)\n",
    "\n",
    "# 22847 different tokens in full lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADP_count</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>CCONJ_count</th>\n",
       "      <th>DET_count</th>\n",
       "      <th>INTJ_count</th>\n",
       "      <th>NOUN_count</th>\n",
       "      <th>NUM_count</th>\n",
       "      <th>PART_count</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>...</th>\n",
       "      <th>X_count</th>\n",
       "      <th>adj_noun_ratio</th>\n",
       "      <th>adv_verb_ratio</th>\n",
       "      <th>bang_count</th>\n",
       "      <th>colon_count</th>\n",
       "      <th>ellipse_count</th>\n",
       "      <th>lparen_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>semicolon_count</th>\n",
       "      <th>sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5204.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>4003.000000</td>\n",
       "      <td>4863.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>543.000000</td>\n",
       "      <td>2256.000000</td>\n",
       "      <td>4732.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.0</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.0</td>\n",
       "      <td>5635.0</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.554392</td>\n",
       "      <td>4.177364</td>\n",
       "      <td>1.587400</td>\n",
       "      <td>1.880839</td>\n",
       "      <td>3.082459</td>\n",
       "      <td>1.169399</td>\n",
       "      <td>5.607986</td>\n",
       "      <td>1.206262</td>\n",
       "      <td>1.435284</td>\n",
       "      <td>2.749155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.656980</td>\n",
       "      <td>2.367340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080213</td>\n",
       "      <td>0.442413</td>\n",
       "      <td>151.974800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.675758</td>\n",
       "      <td>3.799392</td>\n",
       "      <td>1.814904</td>\n",
       "      <td>1.305063</td>\n",
       "      <td>2.880091</td>\n",
       "      <td>0.627872</td>\n",
       "      <td>5.432861</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.867382</td>\n",
       "      <td>2.506438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695852</td>\n",
       "      <td>1.338079</td>\n",
       "      <td>2.417259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382373</td>\n",
       "      <td>0.750584</td>\n",
       "      <td>128.698383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4663.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ADJ_count    ADP_count    ADV_count  CCONJ_count    DET_count  \\\n",
       "count  5635.000000  5204.000000  5635.000000  4003.000000  4863.000000   \n",
       "mean      3.554392     4.177364     1.587400     1.880839     3.082459   \n",
       "std       3.675758     3.799392     1.814904     1.305063     2.880091   \n",
       "min       0.000000     1.000000     0.000000     1.000000     1.000000   \n",
       "25%       1.000000     2.000000     0.000000     1.000000     1.000000   \n",
       "50%       3.000000     3.000000     1.000000     2.000000     2.000000   \n",
       "75%       5.000000     5.000000     2.000000     2.000000     4.000000   \n",
       "max     116.000000   130.000000    41.000000    27.000000    96.000000   \n",
       "\n",
       "       INTJ_count   NOUN_count   NUM_count   PART_count   PRON_count  \\\n",
       "count  183.000000  5635.000000  543.000000  2256.000000  4732.000000   \n",
       "mean     1.169399     5.607986    1.206262     1.435284     2.749155   \n",
       "std      0.627872     5.432861    0.524138     0.867382     2.506438   \n",
       "min      1.000000     0.000000    1.000000     1.000000     1.000000   \n",
       "25%      1.000000     3.000000    1.000000     1.000000     1.000000   \n",
       "50%      1.000000     5.000000    1.000000     1.000000     2.000000   \n",
       "75%      1.000000     7.000000    1.000000     2.000000     4.000000   \n",
       "max      6.000000   193.000000    5.000000    17.000000    64.000000   \n",
       "\n",
       "          ...         X_count  adj_noun_ratio  adv_verb_ratio  bang_count  \\\n",
       "count     ...       20.000000     5635.000000     5635.000000      5635.0   \n",
       "mean      ...        1.200000        1.656980        2.367340         0.0   \n",
       "std       ...        0.695852        1.338079        2.417259         0.0   \n",
       "min       ...        1.000000        0.000000        0.000000         0.0   \n",
       "25%       ...        1.000000        1.000000        0.000000         0.0   \n",
       "50%       ...        1.000000        1.400000        2.000000         0.0   \n",
       "75%       ...        1.000000        2.000000        3.500000         0.0   \n",
       "max       ...        4.000000       14.000000       18.000000         0.0   \n",
       "\n",
       "       colon_count  ellipse_count  lparen_count  quote_count  semicolon_count  \\\n",
       "count  5635.000000         5635.0        5635.0  5635.000000      5635.000000   \n",
       "mean      0.057675            0.0           0.0     0.080213         0.442413   \n",
       "std       0.258424            0.0           0.0     0.382373         0.750584   \n",
       "min       0.000000            0.0           0.0     0.000000         0.000000   \n",
       "25%       0.000000            0.0           0.0     0.000000         0.000000   \n",
       "50%       0.000000            0.0           0.0     0.000000         0.000000   \n",
       "75%       0.000000            0.0           0.0     0.000000         1.000000   \n",
       "max       3.000000            0.0           0.0    10.000000         6.000000   \n",
       "\n",
       "          sent_len  \n",
       "count  5635.000000  \n",
       "mean    151.974800  \n",
       "std     128.698383  \n",
       "min      21.000000  \n",
       "25%      84.000000  \n",
       "50%     129.000000  \n",
       "75%     192.000000  \n",
       "max    4663.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mws_df = train_df[train_df.author == 'MWS']\n",
    "hpl_df = train_df[train_df.author == 'HPL']\n",
    "eap_df = train_df[train_df.author == 'EAP']\n",
    "\n",
    "cutoff = min([mws_df.shape[0], hpl_df.shape[0], eap_df.shape[0]])\n",
    "\n",
    "# equalize corpus sizes to avoid bias during exploration\n",
    "mws_df = mws_df[:cutoff]\n",
    "hpl_df = hpl_df[:cutoff]\n",
    "eap_df = eap_df[:cutoff]\n",
    "\n",
    "mws_lexicon = Utils.build_lexicon(mws_df.text, STOPWORDS)\n",
    "hpl_lexicon = Utils.build_lexicon(hpl_df.text, STOPWORDS)\n",
    "eap_lexicon = Utils.build_lexicon(eap_df.text, STOPWORDS)\n",
    "\n",
    "# sanity check\n",
    "assert(cutoff * 3 == len(mws_df) + len(hpl_df) + len(eap_df))\n",
    "\n",
    "# add grammatical features (for exploration this time, not training)\n",
    "mws_gram_feats_df = Extract.gram_feats(mws_df.text, None, None)\n",
    "hpl_gram_feats_df = Extract.gram_feats(hpl_df.text, None, None)\n",
    "eap_gram_feats_df = Extract.gram_feats(eap_df.text, None, None)\n",
    "\n",
    "mws_gram_feats_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like sentence length values are consistently higher by at least a degree of magnitude\n",
    "# so we'll take the log\n",
    "for df in [mws_gram_feats_df, hpl_gram_feats_df, eap_gram_feats_df]:\n",
    "    df['sent_len'] = df['sent_len'].apply(lambda x: math.log(x))\n",
    "    df.rename(inplace=True, columns={'sent_len': 'log_sent_len'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER exploration\n",
    "\n",
    "# avoiding NER for three reasons:\n",
    "# features very sparse\n",
    "# features seem content-specific, so may contribute to misprediction\n",
    "# should we add data from the same authors about other topics\n",
    "\n",
    "NER = False\n",
    "if NER:\n",
    "    import spacy\n",
    "    spacy_mdl = spacy.load('en_core_web_sm')\n",
    "\n",
    "    def sent_to_ents(sent, spacy):\n",
    "        sent = spacy(sent)\n",
    "        ents = []\n",
    "        for ent in sent.ents:\n",
    "            ents.append(ent.text + ':' + ent.label_)\n",
    "        return ents\n",
    "\n",
    "    entities = []\n",
    "    for i in range(1500):\n",
    "        sent = valdata.iloc[i].text\n",
    "        ents = sent_to_ents(sent, spacy_mdl)\n",
    "        entities.append(ents)\n",
    " \n",
    "\n",
    "# example entities list HERE\n",
    "# many sentences don't have any entities, like below\n",
    "#'In whatever way the shifting is managed, it is of course concealed at every step from observation.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NER:\n",
    "    import statistics as stat\n",
    "    entity_freq = [len(x) for x in entities]\n",
    "\n",
    "\n",
    "    print(\"stats for NER within a sample group: \\n\")\n",
    "    print(\"min: {} \\nmax: {} \\nmean: {} \\nstdev: {}\" \\\n",
    "          .format(min(entity_freq), max(entity_freq), stat.mean(entity_freq), stat.stdev(entity_freq)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration - visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example MWS sentence: \n",
      "3    How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.\n",
      "\n",
      "Example HPL sentence: \n",
      "1    It never once occurred to me that the fumbling might be a mere mistake.\n",
      "\n",
      "Example EAP sentence: \n",
      "0    This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data viz\n",
    "\n",
    "def plot_word_freq(lexicon, name, quantity=20):\n",
    "    plt.rcdefaults()\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    elems = [x[0] for x in lexicon[:quantity]]\n",
    "    y_pos = np.arange(quantity)\n",
    "    vals = [x[1] for x in lexicon[:quantity]]\n",
    "\n",
    "    ax.barh(y_pos, vals, align='center',\n",
    "            color='green', ecolor='black')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(elems)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_xlabel('Corpus-wide frequency')\n",
    "    ax.set_title(name + ' - Word Frequencies')\n",
    "\n",
    "    plt.show()\n",
    " \n",
    "authors = {'MWS': mws_lexicon, 'HPL': hpl_lexicon, 'EAP': eap_lexicon}\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(\"Example MWS sentence: \\n{}\\n\".format(mws_df.text[:1].to_string()))\n",
    "print(\"Example HPL sentence: \\n{}\\n\".format(hpl_df.text[:1].to_string()))\n",
    "print(\"Example EAP sentence: \\n{}\\n\".format(eap_df.text[:1].to_string()))\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "\n",
    "# for key in authors: \n",
    "#     plot_word_freq(authors[key], key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(df, subset):\n",
    "    features = {\n",
    "        'tag_features': [\n",
    "             'ADJ_count',\n",
    "             'ADP_count',\n",
    "             'ADV_count',\n",
    "             'CCONJ_count',\n",
    "             'DET_count',\n",
    "             'NOUN_count',\n",
    "             'PRON_count',\n",
    "             'VERB_count'],\n",
    "        'punc_features': [\n",
    "            'bang_count',\n",
    "            'colon_count',\n",
    "            'ellipse_count',\n",
    "            'lparen_count',\n",
    "            'quote_count',\n",
    "            'semicolon_count'],\n",
    "        'ratio_features': [\n",
    "             'adj_noun_ratio',\n",
    "             'adv_verb_ratio',\n",
    "             'log_sent_len']\n",
    "    }\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    boxplot = df.boxplot(column=features[subset], \\\n",
    "        showfliers=False, fontsize=6, figsize=None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box(mws_gram_feats_df, 'ratio_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box(hpl_gram_feats_df, 'ratio_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box(eap_gram_feats_df, 'ratio_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box(mws_gram_feats_df, 'tag_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box(hpl_gram_feats_df, 'tag_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box(eap_gram_feats_df, 'tag_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box(mws_gram_feats_df, 'punc_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box(hpl_gram_feats_df, 'punc_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box(eap_gram_feats_df, 'punc_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADP_count</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>CCONJ_count</th>\n",
       "      <th>DET_count</th>\n",
       "      <th>INTJ_count</th>\n",
       "      <th>NOUN_count</th>\n",
       "      <th>NUM_count</th>\n",
       "      <th>PART_count</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>...</th>\n",
       "      <th>X_count</th>\n",
       "      <th>adj_noun_ratio</th>\n",
       "      <th>adv_verb_ratio</th>\n",
       "      <th>bang_count</th>\n",
       "      <th>colon_count</th>\n",
       "      <th>ellipse_count</th>\n",
       "      <th>lparen_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>semicolon_count</th>\n",
       "      <th>log_sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5018.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>3307.000000</td>\n",
       "      <td>5004.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>1949.000000</td>\n",
       "      <td>4080.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.0</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.0</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.918012</td>\n",
       "      <td>4.378836</td>\n",
       "      <td>1.936646</td>\n",
       "      <td>1.728152</td>\n",
       "      <td>3.605516</td>\n",
       "      <td>1.439306</td>\n",
       "      <td>5.114286</td>\n",
       "      <td>1.504624</td>\n",
       "      <td>1.420729</td>\n",
       "      <td>2.127696</td>\n",
       "      <td>...</td>\n",
       "      <td>1.989130</td>\n",
       "      <td>1.692336</td>\n",
       "      <td>1.787072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022538</td>\n",
       "      <td>0.011180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165217</td>\n",
       "      <td>0.172671</td>\n",
       "      <td>4.710147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.850061</td>\n",
       "      <td>3.656925</td>\n",
       "      <td>2.000106</td>\n",
       "      <td>1.218010</td>\n",
       "      <td>2.864495</td>\n",
       "      <td>0.995959</td>\n",
       "      <td>4.344305</td>\n",
       "      <td>1.394070</td>\n",
       "      <td>0.765330</td>\n",
       "      <td>1.478494</td>\n",
       "      <td>...</td>\n",
       "      <td>1.558349</td>\n",
       "      <td>1.518619</td>\n",
       "      <td>1.810267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157714</td>\n",
       "      <td>0.361998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.790786</td>\n",
       "      <td>0.523666</td>\n",
       "      <td>0.710429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.044522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.204693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.744932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.220356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.334982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ADJ_count    ADP_count    ADV_count  CCONJ_count    DET_count  \\\n",
       "count  5635.000000  5018.000000  5635.000000  3307.000000  5004.000000   \n",
       "mean      2.918012     4.378836     1.936646     1.728152     3.605516   \n",
       "std       2.850061     3.656925     2.000106     1.218010     2.864495   \n",
       "min       0.000000     1.000000     0.000000     1.000000     1.000000   \n",
       "25%       1.000000     2.000000     1.000000     1.000000     2.000000   \n",
       "50%       2.000000     3.000000     1.000000     1.000000     3.000000   \n",
       "75%       4.000000     6.000000     3.000000     2.000000     5.000000   \n",
       "max      39.000000    64.000000    19.000000    13.000000    45.000000   \n",
       "\n",
       "       INTJ_count   NOUN_count   NUM_count   PART_count   PRON_count  \\\n",
       "count  173.000000  5635.000000  757.000000  1949.000000  4080.000000   \n",
       "mean     1.439306     5.114286    1.504624     1.420729     2.127696   \n",
       "std      0.995959     4.344305    1.394070     0.765330     1.478494   \n",
       "min      1.000000     0.000000    1.000000     1.000000     1.000000   \n",
       "25%      1.000000     2.000000    1.000000     1.000000     1.000000   \n",
       "50%      1.000000     4.000000    1.000000     1.000000     2.000000   \n",
       "75%      2.000000     7.000000    2.000000     2.000000     3.000000   \n",
       "max      8.000000    67.000000   27.000000     8.000000    15.000000   \n",
       "\n",
       "           ...         X_count  adj_noun_ratio  adv_verb_ratio  bang_count  \\\n",
       "count      ...       92.000000     5635.000000     5635.000000      5635.0   \n",
       "mean       ...        1.989130        1.692336        1.787072         0.0   \n",
       "std        ...        1.558349        1.518619        1.810267         0.0   \n",
       "min        ...        1.000000        0.000000        0.000000         0.0   \n",
       "25%        ...        1.000000        0.800000        0.000000         0.0   \n",
       "50%        ...        1.000000        1.400000        1.500000         0.0   \n",
       "75%        ...        2.000000        2.125000        2.500000         0.0   \n",
       "max        ...        9.000000       14.000000       13.000000         0.0   \n",
       "\n",
       "       colon_count  ellipse_count  lparen_count  quote_count  semicolon_count  \\\n",
       "count  5635.000000    5635.000000        5635.0  5635.000000      5635.000000   \n",
       "mean      0.022538       0.011180           0.0     0.165217         0.172671   \n",
       "std       0.157714       0.361998           0.0     0.790786         0.523666   \n",
       "min       0.000000       0.000000           0.0     0.000000         0.000000   \n",
       "25%       0.000000       0.000000           0.0     0.000000         0.000000   \n",
       "50%       0.000000       0.000000           0.0     0.000000         0.000000   \n",
       "75%       0.000000       0.000000           0.0     0.000000         0.000000   \n",
       "max       3.000000      17.000000           0.0    23.000000        11.000000   \n",
       "\n",
       "       log_sent_len  \n",
       "count   5635.000000  \n",
       "mean       4.710147  \n",
       "std        0.710429  \n",
       "min        3.044522  \n",
       "25%        4.204693  \n",
       "50%        4.744932  \n",
       "75%        5.220356  \n",
       "max        7.334982  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eap_gram_feats_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strangely enough, grepping through the raw input indeed shows that no bang characters exist\n",
    "# the boxplots indicate that the grammatical features indeed don't seem to have much \n",
    "# predictive power, so we'll try other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection, training, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_run(X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "    lin_clf = LinearSVC()\n",
    "    lin_clf.fit(X_train, Y_train) \n",
    "    \n",
    "    preds = lin_clf.predict(X_val)\n",
    "    accuracy = Eval.get_accuracy(preds, Y_val)\n",
    "    print(\"Val Accuracy: \", accuracy)\n",
    "    \n",
    "    preds = lin_clf.predict(X_test)\n",
    "    accuracy = Eval.get_accuracy(preds, Y_test)\n",
    "    print(\"Test Accuracy: \", accuracy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.7318692543411645\n",
      "Test Accuracy:  0.7199795605518651\n"
     ]
    }
   ],
   "source": [
    "train_n_run(X_train, Y_train, X_val, Y_val, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[579 100  99]\n",
      " [219 279  85]\n",
      " [270  93 234]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a265ccc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# error analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "conf_mat = confusion_matrix(Y_val, preds)\n",
    "\n",
    "\n",
    "# NOTE: this function taken from: \n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = 500\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "print(conf_mat)\n",
    "plot_confusion_matrix(conf_mat, classes=lin_clf.classes_,\n",
    "                      title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [good place to insert val vs. test metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished at:  Sun Dec  9 00:18:56 2018\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timenow = time.asctime( time.localtime(time.time()) )\n",
    "print(\"Finished at: \", timenow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
