{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"./code/\")\n",
    "from Utils import Utils # student's library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "#train_df.id.nunique()\n",
    "# 19579\n",
    "\n",
    "#train_df.author.unique()\n",
    "# array(['EAP', 'HPL', 'MWS'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 0, 'id': 0, 'text': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Utils.check_for_nulls(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_df = train_df[:20]\n",
    "short_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 35),\n",
       " ('the', 35),\n",
       " ('and', 22),\n",
       " ('i', 18),\n",
       " ('to', 15),\n",
       " ('a', 12),\n",
       " ('his', 11),\n",
       " ('my', 9),\n",
       " ('that', 9),\n",
       " ('in', 9),\n",
       " ('he', 7),\n",
       " ('as', 5),\n",
       " ('with', 4),\n",
       " ('not', 4),\n",
       " ('for', 4),\n",
       " ('this', 3),\n",
       " ('being', 3),\n",
       " ('was', 3),\n",
       " ('all', 3),\n",
       " ('at', 3),\n",
       " ('you', 3),\n",
       " ('could', 3),\n",
       " ('no', 2),\n",
       " ('so', 2),\n",
       " ('from', 2),\n",
       " ('an', 2),\n",
       " ('how', 2),\n",
       " ('we', 2),\n",
       " ('on', 2),\n",
       " ('heart', 2),\n",
       " ('but', 2),\n",
       " ('very', 2),\n",
       " ('had', 2),\n",
       " ('almost', 2),\n",
       " ('her', 2),\n",
       " ('me', 1),\n",
       " ('might', 1),\n",
       " ('its', 1),\n",
       " ('without', 1),\n",
       " ('it', 1),\n",
       " ('never', 1),\n",
       " ('be', 1),\n",
       " ('snuff', 1),\n",
       " ('which,', 1),\n",
       " ('hill,', 1),\n",
       " ('took', 1),\n",
       " ('air', 1),\n",
       " ('looked', 1),\n",
       " ('by', 1),\n",
       " ('even', 1),\n",
       " ('your', 1),\n",
       " ('when', 1),\n",
       " ('paid', 1),\n",
       " ('him', 1),\n",
       " ('felt', 1),\n",
       " ('here', 1),\n",
       " ('say', 1),\n",
       " ('long', 1),\n",
       " ('little', 1),\n",
       " ('eyes', 1),\n",
       " ('nor', 1),\n",
       " ('shall', 1),\n",
       " ('few', 1),\n",
       " ('and,', 1),\n",
       " ('needed', 1),\n",
       " ('native', 1),\n",
       " ('they', 1),\n",
       " ('their', 1),\n",
       " ('well', 1),\n",
       " ('process,', 0),\n",
       " ('however,', 0),\n",
       " ('afforded', 0),\n",
       " ('means', 0),\n",
       " ('ascertaining', 0),\n",
       " ('dimensions', 0),\n",
       " ('dungeon;', 0),\n",
       " ('make', 0),\n",
       " ('circuit,', 0),\n",
       " ('return', 0),\n",
       " ('point', 0),\n",
       " ('whence', 0),\n",
       " ('set', 0),\n",
       " ('out,', 0),\n",
       " ('aware', 0),\n",
       " ('fact;', 0),\n",
       " ('perfectly', 0),\n",
       " ('uniform', 0),\n",
       " ('seemed', 0),\n",
       " ('wall.', 0),\n",
       " ('once', 0),\n",
       " ('occurred', 0),\n",
       " ('fumbling', 0),\n",
       " ('mere', 0),\n",
       " ('mistake.', 0),\n",
       " ('left', 0),\n",
       " ('hand', 0),\n",
       " ('gold', 0),\n",
       " ('box,', 0),\n",
       " ('capered', 0),\n",
       " ('down', 0),\n",
       " ('cutting', 0),\n",
       " ('manner', 0),\n",
       " ('fantastic', 0),\n",
       " ('steps,', 0),\n",
       " ('incessantly', 0),\n",
       " ('greatest', 0),\n",
       " ('possible', 0),\n",
       " ('self', 0),\n",
       " ('satisfaction.', 0),\n",
       " ('lovely', 0),\n",
       " ('is', 0),\n",
       " ('spring', 0),\n",
       " ('windsor', 0),\n",
       " ('terrace', 0),\n",
       " ('sixteen', 0),\n",
       " ('fertile', 0),\n",
       " ('counties', 0),\n",
       " ('spread', 0),\n",
       " ('beneath,', 0),\n",
       " ('speckled', 0),\n",
       " ('happy', 0),\n",
       " ('cottages', 0),\n",
       " ('wealthier', 0),\n",
       " ('towns,', 0),\n",
       " ('former', 0),\n",
       " ('years,', 0),\n",
       " ('cheering', 0),\n",
       " ('fair.', 0),\n",
       " ('finding', 0),\n",
       " ('nothing', 0),\n",
       " ('else,', 0),\n",
       " ('gold,', 0),\n",
       " ('superintendent', 0),\n",
       " ('abandoned', 0),\n",
       " ('attempts;', 0),\n",
       " ('perplexed', 0),\n",
       " ('look', 0),\n",
       " ('occasionally', 0),\n",
       " ('steals', 0),\n",
       " ('over', 0),\n",
       " ('countenance', 0),\n",
       " ('sits', 0),\n",
       " ('thinking', 0),\n",
       " ('desk.', 0),\n",
       " ('youth', 0),\n",
       " ('passed', 0),\n",
       " ('solitude,', 0),\n",
       " ('best', 0),\n",
       " ('years', 0),\n",
       " ('spent', 0),\n",
       " ('under', 0),\n",
       " ('gentle', 0),\n",
       " ('feminine', 0),\n",
       " ('fosterage,', 0),\n",
       " ('has', 0),\n",
       " ('refined', 0),\n",
       " ('groundwork', 0),\n",
       " ('character', 0),\n",
       " ('cannot', 0),\n",
       " ('overcome', 0),\n",
       " ('intense', 0),\n",
       " ('distaste', 0),\n",
       " ('usual', 0),\n",
       " ('brutality', 0),\n",
       " ('exercised', 0),\n",
       " ('board', 0),\n",
       " ('ship:', 0),\n",
       " ('have', 0),\n",
       " ('believed', 0),\n",
       " ('necessary,', 0),\n",
       " ('heard', 0),\n",
       " ('mariner', 0),\n",
       " ('equally', 0),\n",
       " ('noted', 0),\n",
       " ('kindliness', 0),\n",
       " ('respect', 0),\n",
       " ('obedience', 0),\n",
       " ('crew,', 0),\n",
       " ('myself', 0),\n",
       " ('peculiarly', 0),\n",
       " ('fortunate', 0),\n",
       " ('able', 0),\n",
       " ('secure', 0),\n",
       " ('services.', 0),\n",
       " ('astronomer,', 0),\n",
       " ('perhaps,', 0),\n",
       " ('point,', 0),\n",
       " ('refuge', 0),\n",
       " ('suggestion', 0),\n",
       " ('non', 0),\n",
       " ('luminosity;', 0),\n",
       " ('analogy', 0),\n",
       " ('suddenly', 0),\n",
       " ('let', 0),\n",
       " ('fall.', 0),\n",
       " ('surcingle', 0),\n",
       " ('hung', 0),\n",
       " ('ribands', 0),\n",
       " ('body.', 0),\n",
       " ('knew', 0),\n",
       " ('yourself', 0),\n",
       " (\"'stereotomy'\", 0),\n",
       " ('brought', 0),\n",
       " ('think', 0),\n",
       " ('atomies,', 0),\n",
       " ('thus', 0),\n",
       " ('theories', 0),\n",
       " ('epicurus;', 0),\n",
       " ('since,', 0),\n",
       " ('discussed', 0),\n",
       " ('subject', 0),\n",
       " ('ago,', 0),\n",
       " ('mentioned', 0),\n",
       " ('singularly,', 0),\n",
       " ('yet', 0),\n",
       " ('notice,', 0),\n",
       " ('vague', 0),\n",
       " ('guesses', 0),\n",
       " ('noble', 0),\n",
       " ('greek', 0),\n",
       " ('met', 0),\n",
       " ('confirmation', 0),\n",
       " ('late', 0),\n",
       " ('nebular', 0),\n",
       " ('cosmogony,', 0),\n",
       " ('avoid', 0),\n",
       " ('casting', 0),\n",
       " ('upward', 0),\n",
       " ('great', 0),\n",
       " ('nebula', 0),\n",
       " ('orion,', 0),\n",
       " ('certainly', 0),\n",
       " ('expected', 0),\n",
       " ('would', 0),\n",
       " ('do', 0),\n",
       " ('so.', 0),\n",
       " ('confess', 0),\n",
       " ('neither', 0),\n",
       " ('structure', 0),\n",
       " ('languages,', 0),\n",
       " ('code', 0),\n",
       " ('governments,', 0),\n",
       " ('politics', 0),\n",
       " ('various', 0),\n",
       " ('states', 0),\n",
       " ('possessed', 0),\n",
       " ('attractions', 0),\n",
       " ('me.', 0),\n",
       " ('find', 0),\n",
       " ('can', 0),\n",
       " ('feel', 0),\n",
       " ('injuries;', 0),\n",
       " ('learn', 0),\n",
       " ('dread', 0),\n",
       " ('revenge\"', 0),\n",
       " ('days', 0),\n",
       " ('after', 0),\n",
       " ('arrived.', 0),\n",
       " ('barricaded', 0),\n",
       " ('ourselves,', 0),\n",
       " ('present', 0),\n",
       " ('were', 0),\n",
       " ('secure.', 0),\n",
       " ('herbert', 0),\n",
       " ('west', 0),\n",
       " ('fresh', 0),\n",
       " ('bodies', 0),\n",
       " ('because', 0),\n",
       " ('life', 0),\n",
       " ('work', 0),\n",
       " ('reanimation', 0),\n",
       " ('dead.', 0),\n",
       " ('farm', 0),\n",
       " ('like', 0),\n",
       " ('grounds', 0),\n",
       " ('extended', 0),\n",
       " ('back', 0),\n",
       " ('deeply', 0),\n",
       " ('up', 0),\n",
       " ('wheaton', 0),\n",
       " ('street.', 0),\n",
       " ('glance', 0),\n",
       " ('will', 0),\n",
       " ('show', 0),\n",
       " ('fallacy', 0),\n",
       " ('idea.', 0),\n",
       " ('escaped', 0),\n",
       " ('me,', 0),\n",
       " ('must', 0),\n",
       " ('commence', 0),\n",
       " ('destructive', 0),\n",
       " ('endless', 0),\n",
       " ('journey', 0),\n",
       " ('across', 0),\n",
       " ('mountainous', 0),\n",
       " ('ices', 0),\n",
       " ('ocean,', 0),\n",
       " ('amidst', 0),\n",
       " ('cold', 0),\n",
       " ('inhabitants', 0),\n",
       " ('endure', 0),\n",
       " ('which', 0),\n",
       " ('i,', 0),\n",
       " ('genial', 0),\n",
       " ('sunny', 0),\n",
       " ('climate,', 0),\n",
       " ('hope', 0),\n",
       " ('survive.', 0),\n",
       " ('these', 0),\n",
       " ('speeches', 0),\n",
       " ('gave,', 0),\n",
       " ('course,', 0),\n",
       " ('own', 0),\n",
       " ('interpretation;', 0),\n",
       " ('fancying,', 0),\n",
       " ('doubt,', 0),\n",
       " ('events', 0),\n",
       " ('should', 0),\n",
       " ('come', 0),\n",
       " ('into', 0),\n",
       " ('possession', 0),\n",
       " ('vast', 0),\n",
       " ('quantities', 0),\n",
       " ('ready', 0),\n",
       " ('money;', 0),\n",
       " ('provided', 0),\n",
       " ('them', 0),\n",
       " ('owed,', 0),\n",
       " ('trifle', 0),\n",
       " ('more,', 0),\n",
       " ('consideration', 0),\n",
       " ('services,', 0),\n",
       " ('dare', 0),\n",
       " ('cared', 0),\n",
       " ('what', 0),\n",
       " ('became', 0),\n",
       " ('either', 0),\n",
       " ('soul', 0),\n",
       " ('or', 0),\n",
       " ('carcass.', 0),\n",
       " ('sprightliness', 0),\n",
       " ('undue', 0),\n",
       " ('excitement,', 0),\n",
       " ('placid', 0),\n",
       " ('reposed', 0),\n",
       " ('contented', 0),\n",
       " ('love,', 0),\n",
       " ('children,', 0),\n",
       " ('beauty', 0),\n",
       " ('surrounding', 0),\n",
       " ('nature.', 0),\n",
       " ('went', 0),\n",
       " ('far', 0),\n",
       " ('speak', 0),\n",
       " ('slightly', 0),\n",
       " ('hectic', 0),\n",
       " ('cough', 0),\n",
       " ('one', 0),\n",
       " ('time,', 0),\n",
       " ('been', 0),\n",
       " ('troubled', 0),\n",
       " ('chronic', 0),\n",
       " ('rheumatism', 0),\n",
       " ('twinge', 0),\n",
       " ('hereditary', 0),\n",
       " ('gout', 0),\n",
       " ('conclusion,', 0),\n",
       " ('disagreeable', 0),\n",
       " ('inconvenient,', 0),\n",
       " ('hitherto', 0),\n",
       " ('carefully', 0),\n",
       " ('concealed,', 0),\n",
       " ('weakness', 0),\n",
       " ('eyes.', 0),\n",
       " ('facial', 0),\n",
       " ('aspect,', 0),\n",
       " ('too,', 0),\n",
       " ('remarkable', 0),\n",
       " ('maturity;', 0),\n",
       " ('though', 0),\n",
       " ('shared', 0),\n",
       " (\"mother's\", 0),\n",
       " (\"grandfather's\", 0),\n",
       " ('chinlessness,', 0),\n",
       " ('firm', 0),\n",
       " ('precociously', 0),\n",
       " ('shaped', 0),\n",
       " ('nose', 0),\n",
       " ('united', 0),\n",
       " ('expression', 0),\n",
       " ('large,', 0),\n",
       " ('dark,', 0),\n",
       " ('latin', 0),\n",
       " ('give', 0),\n",
       " ('quasi', 0),\n",
       " ('adulthood', 0),\n",
       " ('nigh', 0),\n",
       " ('preternatural', 0),\n",
       " ('intelligence.', 0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(sentence):\n",
    "    return sentence.split(' ')\n",
    "\n",
    "def build_lexicon(sents):\n",
    "    lex = {}\n",
    "    for sent in sents:\n",
    "        words = tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            if word in lex:\n",
    "                lex[word] = lex[word] + 1\n",
    "            else:\n",
    "                lex[word] = 1\n",
    "    return sorted(lex.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "train_lex = build_lexicon(short_df.text)   \n",
    "train_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short_sents = [tokenize(x) for x in list(short_df.text)]\n",
    "# short_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "# http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/\n",
    "\n",
    "# this glove code is wrong type for later work\n",
    "# with open(\"data/glove.42B.300d.txt\", \"rb\") as lines:\n",
    "#     w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "#            for line in lines}\n",
    "\n",
    "\n",
    "# let X be a list of tokenized texts (i.e. list of lists of tokens)\n",
    "# sentences param is token lists\n",
    "model = gensim.models.Word2Vec(short_sents, size=100)\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.vectors))\n",
    "type(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['of', 'the', 'and', 'I', 'to', 'a', 'his', 'my', 'that', 'in', 'he', 'as', 'with', 'not', 'for'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(w2v.keys())[9990:9999]\n",
    "# [b'iconic',\n",
    "#  b'erp',\n",
    "#  b'crest',\n",
    "#  b'radius',\n",
    "#  b'spiral',\n",
    "#  b'nyse',\n",
    "#  b'lotion',\n",
    "#  b'oriental',\n",
    "#  b'admire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'owl'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_key = list(w2v.keys())[9999]\n",
    "a_key.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(w2v[str.encode('owl')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MeanEmbeddingVectorizer(object):\n",
    "#     def __init__(self, word2vec):\n",
    "#         self.word2vec = word2vec\n",
    "#         # if a text is empty we should return a vector of zeros\n",
    "#         # with the same dimensionality as all the other vectors\n",
    "#         self.dim = len(word2vec.itervalues().next())\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         return np.array([\n",
    "#             np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "#                     or [np.zeros(self.dim)], axis=0)\n",
    "#             for words in X\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_e_v = MeanEmbeddingVectorizer(w2v)\n",
    "# short_X_train = m_e_v.transform(short_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "#TaggedDocument does not filter or stem\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(short_sents)]\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08544256,  0.0625724 ,  0.09173509,  0.04404997, -0.05501466],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model.infer_vector([\"system\", \"response\"])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is it! just use the output of infer_vector in training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_tagged_doc = TaggedDocument(short_sents[0], [0])\n",
    "# example_tagged_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order of ops:\n",
    "# just grammar features\n",
    "# just tfidf vectorizer\n",
    "# both\n",
    "\n",
    "# kmeans\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = short_df.text\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(corpus)\n",
    "Y_train = short_df.author\n",
    "X_test = vectorizer.transform(short_df.text)\n",
    "Y_test = short_df.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EAP', 'HPL', 'EAP', 'MWS', 'HPL', 'MWS', 'EAP', 'EAP', 'EAP',\n",
       "       'MWS', 'MWS', 'EAP', 'HPL', 'HPL', 'EAP', 'MWS', 'EAP', 'MWS',\n",
       "       'EAP', 'HPL'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear svc\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(X_train, Y_train) \n",
    "\n",
    "\n",
    "preds = lin_clf.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
