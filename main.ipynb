{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/peterkong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# local code\n",
    "sys.path.insert(1, \"./code/\")\n",
    "from Utils import Utils # student's library\n",
    "from Eval import Eval # student's library\n",
    "from Extract import Extract # student's library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "#train_df.id.nunique()\n",
    "# 19579\n",
    "\n",
    "#train_df.author.unique()\n",
    "# array(['EAP', 'HPL', 'MWS'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 0, 'id': 0, 'text': 0}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Utils.check_for_nulls(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_df = train_df[:20]\n",
    "short_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data\n",
    "\n",
    "# regular data\n",
    "#     train: 19580 * .9 rows\n",
    "#     test:  8393 rows\n",
    "#     val:   19580 * .1 rows\n",
    "\n",
    "\n",
    "if os.path.isfile('data/traindata.pickle'):\n",
    "    traindata = pd.read_pickle('data/traindata.pickle')\n",
    "    valdata   = pd.read_pickle('data/valdata.pickle')\n",
    "    testdata  = pd.read_pickle('data/testdata.pickle')\n",
    "else: \n",
    "    VAL_IDX  = math.ceil(len(train_df) * .8)\n",
    "    TEST_IDX = math.ceil(len(train_df) * .9)\n",
    "\n",
    "    traindata = train_df[:VAL_IDX]\n",
    "    valdata   = train_df[VAL_IDX:TEST_IDX]\n",
    "    testdata  = train_df[TEST_IDX:]\n",
    "\n",
    "    print(VAL_IDX, TEST_IDX)\n",
    "\n",
    "    traindata.to_pickle('data/traindata.pickle')\n",
    "    valdata.to_pickle('data/valdata.pickle')\n",
    "    testdata.to_pickle('data/testdata.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindata: 15664, valdata: 1958, testdata: 1957\n"
     ]
    }
   ],
   "source": [
    "print(\"traindata: {}, valdata: {}, testdata: {}\".format(len(traindata), len(valdata), len(testdata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammatical feature engineering \n",
    "# we want to include stopwords here\n",
    "\n",
    "if os.path.isfile('data/train_gram_feats.pickle'):\n",
    "    print(\"reading gram feats from pickle\")\n",
    "    train_gram_feats_df = pd.read_pickle('data/train_gram_feats_df.pickle')\n",
    "    val_gram_feats_df   = pd.read_pickle('data/val_gram_feats_df.pickle')\n",
    "    test_gram_feats_df  = pd.read_pickle('data/test_gram_feats_df.pickle')\n",
    "else:\n",
    "    seq_no = None\n",
    "    train_gram_feats_df = Extract.gram_feats(traindata.text, None, seq_no)\n",
    "\n",
    "    # need to remember so that val/test process\n",
    "    # does not add additional columns\n",
    "    GRAM_FEAT_LIST = list(train_gram_feats_df.columns)\n",
    "\n",
    "    val_gram_feats_df = Extract.gram_feats(valdata.text, GRAM_FEAT_LIST, seq_no)\n",
    "    test_gram_feats_df = Extract.gram_feats(testdata.text, GRAM_FEAT_LIST, seq_no)\n",
    "\n",
    "    # there are 21 columns excluding sequence columns \n",
    "    # 7ary sequence columns can generate up to 2187\n",
    "    \n",
    "    train_gram_feats_df.to_pickle('data/train_gram_feats_df.pickle')\n",
    "    val_gram_feats_df.to_pickle('data/val_gram_feats_df.pickle')\n",
    "    test_gram_feats_df.to_pickle('data/test_gram_feats_df.pickle')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15664, 23)\n",
      "(1958, 23)\n",
      "(1957, 23)\n"
     ]
    }
   ],
   "source": [
    "# removes a singleton feature\n",
    "for df in train_gram_feats_df, val_gram_feats_df, test_gram_feats_df:\n",
    "    if 'SYM_count' in list(df.columns):\n",
    "        df.drop('SYM_count', axis=1, inplace=True)\n",
    "        \n",
    "print(train_gram_feats_df.shape)\n",
    "print(val_gram_feats_df.shape)\n",
    "print(test_gram_feats_df.shape)\n",
    "\n",
    "#set(GRAM_FEAT_LIST) - set(list(val_gram_feats_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15664, 23)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gram_feats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textual feature engineering\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=STOPWORDS, max_features=100)\n",
    "\n",
    "train_text_feats = vectorizer.fit_transform(traindata.text)\n",
    "Y_train = traindata.author \n",
    "\n",
    "val_text_feats = vectorizer.transform(valdata.text) \n",
    "Y_val = list(valdata.author)\n",
    "\n",
    "test_text_feats = vectorizer.transform(testdata.text) \n",
    "Y_test = list(testdata.author)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15664, 100)\n",
      "(1958, 100)\n",
      "(1957, 100)\n",
      "(15664, 100)\n",
      "(1958, 100)\n",
      "(1957, 100)\n"
     ]
    }
   ],
   "source": [
    "#convert text feats to pandas\n",
    "print(train_text_feats.shape)\n",
    "print(val_text_feats.shape)\n",
    "print(test_text_feats.shape)\n",
    "\n",
    "cols = [\"text_\" + str(x) for x in range(train_text_feats.shape[1])]\n",
    "\n",
    "train_text_feats_df = pd.DataFrame(train_text_feats.todense(), index=None, columns=cols)\n",
    "val_text_feats_df = pd.DataFrame(val_text_feats.todense(), index=None, columns=cols)\n",
    "test_text_feats_df = pd.DataFrame(test_text_feats.todense(), index=None, columns=cols)\n",
    "\n",
    "print(train_text_feats_df.shape)\n",
    "print(val_text_feats_df.shape)\n",
    "print(test_text_feats_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15664, 23)\n",
      "(1958, 23)\n",
      "(1957, 23)\n"
     ]
    }
   ],
   "source": [
    "# concatenating features\n",
    "\n",
    "X_train = train_gram_feats_df.fillna(0)#.join(train_text_feats_df).fillna(0)\n",
    "X_val = val_gram_feats_df.fillna(0)#.join(val_text_feats_df).fillna(0)\n",
    "X_test = test_gram_feats_df.fillna(0)#.join(test_text_feats_df).fillna(0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.sum(axis=0).sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity checking\n",
    "assert(list(X_train.columns) == list(X_val.columns))\n",
    "assert(list(X_train.columns) == list(X_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "# http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/\n",
    "\n",
    "# this glove code is wrong type for later work\n",
    "# with open(\"data/glove.42B.300d.txt\", \"rb\") as lines:\n",
    "#     w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "#            for line in lines}\n",
    "\n",
    "\n",
    "# let X be a list of tokenized texts (i.e. list of lists of tokens)\n",
    "# sentences param is token lists\n",
    "\n",
    "# model = gensim.models.Word2Vec(short_sents, size=100)\n",
    "# w2v = dict(zip(model.wv.index2word, model.wv.vectors))\n",
    "# type(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(w2v.keys())[9990:9999]\n",
    "# [b'iconic',\n",
    "#  b'erp',\n",
    "#  b'crest',\n",
    "#  b'radius',\n",
    "#  b'spiral',\n",
    "#  b'nyse',\n",
    "#  b'lotion',\n",
    "#  b'oriental',\n",
    "#  b'admire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_key = list(w2v.keys())[9999]\n",
    "# a_key.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(w2v[str.encode('owl')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "#TaggedDocument does not filter or stem\n",
    "\n",
    "# documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(short_sents)]\n",
    "# model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "# vector = model.infer_vector([\"system\", \"response\"])\n",
    "# vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order of ops:\n",
    "# just grammar features\n",
    "# just tfidf vectorizer\n",
    "# both\n",
    "\n",
    "# kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EAP', 'EAP', 'EAP', ..., 'EAP', 'EAP', 'EAP'], dtype=object)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear svc\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(X_train, Y_train) \n",
    "preds = lin_clf.predict(X_val)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4964249233912155\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "\n",
    "accuracy = Eval.get_accuracy(preds, Y_val)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Extract\n",
    "import Utils\n",
    "importlib.reload(Extract)\n",
    "importlib.reload(Utils)\n",
    "from Utils import Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration\n",
    "\n",
    "\n",
    "mws_df = train_df[train_df.author == 'MWS']\n",
    "hpl_df = train_df[train_df.author == 'HPL']\n",
    "eap_df = train_df[train_df.author == 'EAP']\n",
    "\n",
    "cutoff = min([mws_df.shape[0], hpl_df.shape[0], eap_df.shape[0]])\n",
    "\n",
    "# equalize corpus sizes to avoid bias during exploration\n",
    "mws_df = mws_df[:cutoff]\n",
    "hpl_df = hpl_df[:cutoff]\n",
    "eap_df = eap_df[:cutoff]\n",
    "\n",
    "mws_lexicon = Utils.build_lexicon(mws_df.text, STOPWORDS)\n",
    "hpl_lexicon = Utils.build_lexicon(hpl_df.text, STOPWORDS)\n",
    "eap_lexicon = Utils.build_lexicon(eap_df.text, STOPWORDS)\n",
    "\n",
    "# sanity check\n",
    "assert(cutoff * 3 == len(mws_df) + len(hpl_df) + len(eap_df))\n",
    "\n",
    "# add grammatical features (for exploration this time, not training)\n",
    "mws_gram_feats_df = Extract.gram_feats(mws_df.text, None, None)\n",
    "hpl_gram_feats_df = Extract.gram_feats(hpl_df.text, None, None)\n",
    "eap_gram_feats_df = Extract.gram_feats(eap_df.text, None, None)\n",
    "\n",
    "mws_gram_feats_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like sentence length values are consistently higher by at least a degree of magnitude\n",
    "# so we'll take the log\n",
    "for df in [mws_gram_feats_df, hpl_gram_feats_df, eap_gram_feats_df]:\n",
    "    df['sent_len'] = df['sent_len'].apply(lambda x: math.log(x))\n",
    "    df.rename(inplace=True, columns={'sent_len': 'log_sent_len'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example MWS sentence: \n",
      "3    How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.\n",
      "\n",
      "Example HPL sentence: \n",
      "1    It never once occurred to me that the fumbling might be a mere mistake.\n",
      "\n",
      "Example EAP sentence: \n",
      "0    This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data viz\n",
    "\n",
    "def plot_word_freq(lexicon, name, quantity=20):\n",
    "    plt.rcdefaults()\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    elems = [x[0] for x in lexicon[:quantity]]\n",
    "    y_pos = np.arange(quantity)\n",
    "    vals = [x[1] for x in lexicon[:quantity]]\n",
    "\n",
    "    ax.barh(y_pos, vals, align='center',\n",
    "            color='green', ecolor='black')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(elems)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_xlabel('Corpus-wide frequency')\n",
    "    ax.set_title(name + ' - Word Frequencies')\n",
    "\n",
    "    plt.show()\n",
    " \n",
    "authors = {'MWS': mws_lexicon, 'HPL': hpl_lexicon, 'EAP': eap_lexicon}\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(\"Example MWS sentence: \\n{}\\n\".format(mws_df.text[:1].to_string()))\n",
    "print(\"Example HPL sentence: \\n{}\\n\".format(hpl_df.text[:1].to_string()))\n",
    "print(\"Example EAP sentence: \\n{}\\n\".format(eap_df.text[:1].to_string()))\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "\n",
    "# for key in authors: \n",
    "#     plot_word_freq(authors[key], key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6044, 3)\n",
      "(5635, 3)\n",
      "(7900, 3)\n"
     ]
    }
   ],
   "source": [
    "start w violion for just eap, all 23 features (not summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADP_count</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>CCONJ_count</th>\n",
       "      <th>DET_count</th>\n",
       "      <th>INTJ_count</th>\n",
       "      <th>NOUN_count</th>\n",
       "      <th>NUM_count</th>\n",
       "      <th>PART_count</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>...</th>\n",
       "      <th>X_count</th>\n",
       "      <th>adj_noun_ratio</th>\n",
       "      <th>adv_verb_ratio</th>\n",
       "      <th>bang_count</th>\n",
       "      <th>colon_count</th>\n",
       "      <th>ellipse_count</th>\n",
       "      <th>lparen_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>semicolon_count</th>\n",
       "      <th>log_sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.596748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.432928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.540235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADJ_count  ADP_count  ADV_count  CCONJ_count  DET_count  INTJ_count  \\\n",
       "0          6        6.0          2          2.0        2.0         NaN   \n",
       "1         15       11.0          6          4.0        6.0         NaN   \n",
       "2          1        5.0          0          3.0        3.0         NaN   \n",
       "3          3        2.0          0          NaN        1.0         NaN   \n",
       "4          7        6.0          3          4.0        6.0         NaN   \n",
       "\n",
       "   NOUN_count  NUM_count  PART_count  PRON_count      ...       X_count  \\\n",
       "0           6        1.0         NaN         1.0      ...           NaN   \n",
       "1          17        NaN         2.0         7.0      ...           NaN   \n",
       "2           7        NaN         NaN         2.0      ...           NaN   \n",
       "3           3        NaN         1.0         4.0      ...           NaN   \n",
       "4           7        NaN         1.0         4.0      ...           NaN   \n",
       "\n",
       "   adj_noun_ratio  adv_verb_ratio  bang_count  colon_count  ellipse_count  \\\n",
       "0        1.000000        3.000000           0            0              0   \n",
       "1        1.133333        2.666667           0            1              0   \n",
       "2        7.000000        0.000000           0            0              0   \n",
       "3        1.000000        0.000000           0            0              0   \n",
       "4        1.000000        3.000000           0            0              0   \n",
       "\n",
       "   lparen_count  quote_count  semicolon_count  log_sent_len  \n",
       "0             0            0                0      0.514590  \n",
       "1             0            0                0      0.596748  \n",
       "2             0            0                0      0.472115  \n",
       "3             0            0                1      0.432928  \n",
       "4             0            0                0      0.540235  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mws_gram_feats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADP_count</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>CCONJ_count</th>\n",
       "      <th>DET_count</th>\n",
       "      <th>INTJ_count</th>\n",
       "      <th>NOUN_count</th>\n",
       "      <th>NUM_count</th>\n",
       "      <th>PART_count</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>...</th>\n",
       "      <th>X_count</th>\n",
       "      <th>adj_noun_ratio</th>\n",
       "      <th>adv_verb_ratio</th>\n",
       "      <th>bang_count</th>\n",
       "      <th>colon_count</th>\n",
       "      <th>ellipse_count</th>\n",
       "      <th>lparen_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>semicolon_count</th>\n",
       "      <th>sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5204.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>4003.000000</td>\n",
       "      <td>4863.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>543.000000</td>\n",
       "      <td>2256.000000</td>\n",
       "      <td>4732.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.0</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.0</td>\n",
       "      <td>5635.0</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.554392</td>\n",
       "      <td>4.177364</td>\n",
       "      <td>1.587400</td>\n",
       "      <td>1.880839</td>\n",
       "      <td>3.082459</td>\n",
       "      <td>1.169399</td>\n",
       "      <td>5.607986</td>\n",
       "      <td>1.206262</td>\n",
       "      <td>1.435284</td>\n",
       "      <td>2.749155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.656980</td>\n",
       "      <td>2.367340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080213</td>\n",
       "      <td>0.442413</td>\n",
       "      <td>1.563314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.675758</td>\n",
       "      <td>3.799392</td>\n",
       "      <td>1.814904</td>\n",
       "      <td>1.305063</td>\n",
       "      <td>2.880091</td>\n",
       "      <td>0.627872</td>\n",
       "      <td>5.432861</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.867382</td>\n",
       "      <td>2.506438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695852</td>\n",
       "      <td>1.338079</td>\n",
       "      <td>2.417259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382373</td>\n",
       "      <td>0.750584</td>\n",
       "      <td>0.138663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.113344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.488584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.659655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.133860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ADJ_count    ADP_count    ADV_count  CCONJ_count    DET_count  \\\n",
       "count  5635.000000  5204.000000  5635.000000  4003.000000  4863.000000   \n",
       "mean      3.554392     4.177364     1.587400     1.880839     3.082459   \n",
       "std       3.675758     3.799392     1.814904     1.305063     2.880091   \n",
       "min       0.000000     1.000000     0.000000     1.000000     1.000000   \n",
       "25%       1.000000     2.000000     0.000000     1.000000     1.000000   \n",
       "50%       3.000000     3.000000     1.000000     2.000000     2.000000   \n",
       "75%       5.000000     5.000000     2.000000     2.000000     4.000000   \n",
       "max     116.000000   130.000000    41.000000    27.000000    96.000000   \n",
       "\n",
       "       INTJ_count   NOUN_count   NUM_count   PART_count   PRON_count  \\\n",
       "count  183.000000  5635.000000  543.000000  2256.000000  4732.000000   \n",
       "mean     1.169399     5.607986    1.206262     1.435284     2.749155   \n",
       "std      0.627872     5.432861    0.524138     0.867382     2.506438   \n",
       "min      1.000000     0.000000    1.000000     1.000000     1.000000   \n",
       "25%      1.000000     3.000000    1.000000     1.000000     1.000000   \n",
       "50%      1.000000     5.000000    1.000000     1.000000     2.000000   \n",
       "75%      1.000000     7.000000    1.000000     2.000000     4.000000   \n",
       "max      6.000000   193.000000    5.000000    17.000000    64.000000   \n",
       "\n",
       "          ...         X_count  adj_noun_ratio  adv_verb_ratio  bang_count  \\\n",
       "count     ...       20.000000     5635.000000     5635.000000      5635.0   \n",
       "mean      ...        1.200000        1.656980        2.367340         0.0   \n",
       "std       ...        0.695852        1.338079        2.417259         0.0   \n",
       "min       ...        1.000000        0.000000        0.000000         0.0   \n",
       "25%       ...        1.000000        1.000000        0.000000         0.0   \n",
       "50%       ...        1.000000        1.400000        2.000000         0.0   \n",
       "75%       ...        1.000000        2.000000        3.500000         0.0   \n",
       "max       ...        4.000000       14.000000       18.000000         0.0   \n",
       "\n",
       "       colon_count  ellipse_count  lparen_count  quote_count  semicolon_count  \\\n",
       "count  5635.000000         5635.0        5635.0  5635.000000      5635.000000   \n",
       "mean      0.057675            0.0           0.0     0.080213         0.442413   \n",
       "std       0.258424            0.0           0.0     0.382373         0.750584   \n",
       "min       0.000000            0.0           0.0     0.000000         0.000000   \n",
       "25%       0.000000            0.0           0.0     0.000000         0.000000   \n",
       "50%       0.000000            0.0           0.0     0.000000         0.000000   \n",
       "75%       0.000000            0.0           0.0     0.000000         1.000000   \n",
       "max       3.000000            0.0           0.0    10.000000         6.000000   \n",
       "\n",
       "          sent_len  \n",
       "count  5635.000000  \n",
       "mean      1.563314  \n",
       "std       0.138663  \n",
       "min       1.113344  \n",
       "25%       1.488584  \n",
       "50%       1.581000  \n",
       "75%       1.659655  \n",
       "max       2.133860  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mws_gram_feats_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
    "\n",
    "\n",
    "\n",
    "# generate some random test data\n",
    "all_data = [np.random.normal(0, std, 100) for std in range(6, 10)]\n",
    "\n",
    "# plot violin plot\n",
    "axes[0].violinplot(all_data,\n",
    "                   showmeans=False,\n",
    "                   showmedians=True)\n",
    "axes[0].set_title('Violin plot')\n",
    "\n",
    "# plot box plot\n",
    "axes[1].boxplot(all_data)\n",
    "axes[1].set_title('Box plot')\n",
    "\n",
    "# adding horizontal grid lines\n",
    "for ax in axes:\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_xticks([y + 1 for y in range(len(all_data))])\n",
    "    ax.set_xlabel('Four separate samples')\n",
    "    ax.set_ylabel('Observed values')\n",
    "\n",
    "# add x-tick labels\n",
    "plt.setp(axes, xticks=[y + 1 for y in range(len(all_data))],\n",
    "         xticklabels=list(mws_gram_feats_df.columns))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(df, subset):\n",
    "    features = {\n",
    "        'tag_features': [\n",
    "             'ADJ_count',\n",
    "             'ADP_count',\n",
    "             'ADV_count',\n",
    "             'CCONJ_count',\n",
    "             'DET_count',\n",
    "             'NOUN_count',\n",
    "             'PRON_count',\n",
    "             'VERB_count'],\n",
    "        'punc_features': [\n",
    "            'bang_count',\n",
    "            'colon_count',\n",
    "            'ellipse_count',\n",
    "            'lparen_count',\n",
    "            'quote_count',\n",
    "            'semicolon_count'],\n",
    "        'ratio_features': [\n",
    "             'adj_noun_ratio',\n",
    "             'adv_verb_ratio',\n",
    "             'log_sent_len']\n",
    "    }\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    boxplot = df.boxplot(column=features[subset], \\\n",
    "        showfliers=False, fontsize=6, figsize=None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a251b8ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_box(eap_gram_feats_df, 'ratio_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "START HERE: set up tryptich plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bar</th>\n",
       "      <th>foo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.605170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.298317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bar       foo\n",
       "0    1  4.605170\n",
       "1    2  5.298317"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timenow = time.asctime( time.localtime(time.time()) )\n",
    "print(\"Finished at: \", timenow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
